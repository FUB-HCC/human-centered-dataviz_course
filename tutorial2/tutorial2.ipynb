{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gdoSGJp1fRAX"
   },
   "source": [
    "**Data Visualization course - winter semester 2023/24 - FU Berlin**\n",
    "\n",
    "*Tutorials adapted from the [Information Visualization](https://infovis.fh-potsdam.de/tutorials/) course at the FH Potsdam*\n",
    "\n",
    "# Tutorial 2: Data wrangling\n",
    "\n",
    "Welcome back! This tutorial shows you a few tricks for preparing data for visualization. You will see how data can be loaded, parsed, and examined. For this we will continue to work with the **Pandas** package, in particular with the DataFrame data structure, and get to know a few additional helpers. \n",
    "\n",
    "*Just as in the first tutorial, you should be able to run the notebook yourself, edit the contents of all cells, and try things out. Here and there particular opportunities for such edits are highlighted with a pencil.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rGgKjuCxWTrc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6BHcIjBEGbAa"
   },
   "source": [
    "## Loading \n",
    "\n",
    "The first step is to bring the data into the purview of your notebook. So regardless of data structure and format, you need to have access to the data set. We will briefly cover four common ways of loading data into your Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ntNgWbFjAG7c"
   },
   "source": [
    "### Enter data directly\n",
    "\n",
    "The simplest way to add data to your notebook is to enter it verbatim into the notebook as we have seen with the capital cities in the first tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 706,
     "status": "ok",
     "timestamp": 1598364864944,
     "user": {
      "displayName": "Marian D√∂rk",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqiajTdRS6NXELnqFzS3NNM3uxy6nUDGSMCjvAjw=s64",
      "userId": "05248840544598202773"
     },
     "user_tz": -120
    },
    "id": "KCLYK8ZTSN0d",
    "outputId": "1f3d1b29-0b30-44d5-83d1-9efaa901faab"
   },
   "outputs": [],
   "source": [
    "cities = pd.DataFrame({\n",
    "  \"name\": [\"Athens\", \"Bratislava\", \"Copenhagen\", \"Dublin\"],\n",
    "  \"area\": [39, 367.6, 86.2, 115],\n",
    "  \"elevation\": [170, 152, 14, 20],\n",
    "  \"population\": [664046, 429564, 602481, 553165]\n",
    "  }\n",
    ")\n",
    "\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y94kj2Doloen"
   },
   "source": [
    "‚úèÔ∏è *Add a column for years when you have visited or plan to visit these cities. You can made up some years, if needed.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Q9g3MkXqlcz"
   },
   "source": [
    "### Open a local file\n",
    "\n",
    "You might also want to open a local file. We can open a file using Python's built-in `Zipfile` method in a context manager, after which we can `read()` its contents into the variable `covid_json`. The file is automatically closed when the context manager block is left. In this case the data is in the JSON format, which we will need to parse. We'll get to this later. You can open all kinds of formats. Here we know that we are dealing with a JSON file because of its extension.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 696,
     "status": "ok",
     "timestamp": 1598364864945,
     "user": {
      "displayName": "Marian D√∂rk",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqiajTdRS6NXELnqFzS3NNM3uxy6nUDGSMCjvAjw=s64",
      "userId": "05248840544598202773"
     },
     "user_tz": -120
    },
    "id": "-zYvVtNatR0N",
    "outputId": "cda41222-71c3-4c40-a507-9e8a3b1d604b"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile(\"owid-covid-data.zip\", 'r') as file:\n",
    "    covid_json = file.read('owid-covid-data.json')\n",
    "\n",
    "covid_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NH5QGv2oqcZI"
   },
   "source": [
    "### Get data via a URL\n",
    "\n",
    "There are some methods that can directly load a dataset via a URL, i.e., a web address. For others you might have to retrieve the file first to continue parsing it. The `requests` package helps you to send HTTP requests and retrieve the responses. \n",
    "\n",
    "In the following, the news feed of Tagesschau is retrieved via an HTTP GET request. Note that the news feed is made available as an XML format; of course you can retrieve all kinds of file formats using this method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1918,
     "status": "ok",
     "timestamp": 1598364866180,
     "user": {
      "displayName": "Marian D√∂rk",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqiajTdRS6NXELnqFzS3NNM3uxy6nUDGSMCjvAjw=s64",
      "userId": "05248840544598202773"
     },
     "user_tz": -120
    },
    "id": "Q_688jMurG0G",
    "outputId": "04d7f83c-4b93-494d-a481-f420fddf7883"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get('https://www.tagesschau.de/infoservices/alle-meldungen-100~rss2.xml')\n",
    "response\n",
    "tagesschau_xml = response.text\n",
    "tagesschau_xml[:1000] # this displays the first 100 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note: To display the data from the XML response in a more structured and readable format, you can use an XML parsing library like xml.etree.ElementTree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1kp9bNB1m5P7"
   },
   "source": [
    "‚úèÔ∏è *Find the news feed for another webpage (e.g., RSS feed from the BBC News website using the URL 'http://feeds.bbci.co.uk/news/rss.xml) and try to load it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TSDRXTkhv009"
   },
   "source": [
    "### Use an API\n",
    "\n",
    "Some web platforms require the use of an API (application programming interface) to get access to their data. Simply put, an API is a structured way to request and retrieve data. Oftentimes it is just a specific way to format the URL.\n",
    "\n",
    "The German National Library offers an [API to query Entity Facts](https://www.dnb.de/EN/Professionell/Metadatendienste/Datenbezug/Entity-Facts/entityFacts_node.html) contained in the GND (Gemeinsame Normdatei). In this case the API provides the data in the JSON format, which has become quite common for web APIs, but you will also encounter many other formats. \n",
    "\n",
    "To retrieve information for a given GND entity by its id, such as the GND entry for the artist [K√§the Kollwitz](https://en.wikipedia.org/wiki/K√§the_Kollwitz) you have to put the `base_url` together with the `gnd_id`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3538,
     "status": "ok",
     "timestamp": 1598364867811,
     "user": {
      "displayName": "Marian D√∂rk",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqiajTdRS6NXELnqFzS3NNM3uxy6nUDGSMCjvAjw=s64",
      "userId": "05248840544598202773"
     },
     "user_tz": -120
    },
    "id": "LSomRaYI56aB",
    "outputId": "522e619b-eca9-41c2-9cb6-d023b3a1c9c2"
   },
   "outputs": [],
   "source": [
    "base_url = \"https://hub.culturegraph.org/entityfacts/\"\n",
    "gnd_id = \"118564943\" # GND identifier from the Wikipedia page on K√§the Kollwitz\n",
    "gnd_response = requests.get(base_url+gnd_id).json()\n",
    "\n",
    "gnd_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using such API is very helpful, for example, when adding additional data to an existing data set. Be aware, very often API keys are needed to access APIs. You need to request them first. An example is the OpenWeatherMap API and how to request data with an API key is shown in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'your_api_key' with your actual API key\n",
    "api_key = 'your_api_key'\n",
    "\n",
    "# Specify the city for which you want weather data\n",
    "city = 'London'\n",
    "\n",
    "# Create the API URL\n",
    "api_url = f'http://api.openweathermap.org/data/2.5/weather?q={city}&appid={api_key}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1nXg3jrQm9K9"
   },
   "source": [
    "‚úèÔ∏è *Prepare an API request with a GND id of another person of German history*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gE3bRFXPuteI"
   },
   "source": [
    "## Parsing \n",
    "\n",
    "Apart from our little cities example, so far we have only loaded the data into unstructured strings. To be able to analyze the data, we have to turn the unstructured strings of symbols into a practical data structure of the DataFrame that we can work with. This process is commonly referred to as ‚Äòparsing‚Äô. \n",
    "\n",
    "As we have seen above, data can come in various file formats, which are in turn more or less appropriate for particular data structures. We'll cover four typical ones in the following section, but we will see more over the course of the tutorials to come.\n",
    "\n",
    "The different ways of loading data (e.g., by file path or URL) are independent from the particular data formats provided. For example, you can load CSV data from a local file or from a web address. While the files typically indicate with the extension what format they have, URLs or APIs may not have these. If it is not clear, you may have to check the documentation or take a peek into the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qu1WltFiAL2H"
   },
   "source": [
    "### CSV\n",
    "\n",
    "The CSV format is probably the most common file format in the context of data analysis and visualization. CSV files contain tabular data that can be viewed and edited in a spreadsheet software such as Excel. CSV stands for [comma-separated values](https://en.wikipedia.org/wiki/Comma-separated_values), which seems to say it all: the data values are separated by commas and each row represents one item. However, there are also CSV files that use separators other than commas, such as tabs and semicolons. \n",
    "\n",
    "Let's load a CSV file! Thankfully Pandas has the convenient `read_csv()` method ready for us, which can open CSV data via a file path or URL, and turns it directly into a DataFrame object. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6455,
     "status": "ok",
     "timestamp": 1598364870740,
     "user": {
      "displayName": "Marian D√∂rk",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqiajTdRS6NXELnqFzS3NNM3uxy6nUDGSMCjvAjw=s64",
      "userId": "05248840544598202773"
     },
     "user_tz": -120
    },
    "id": "O6qOWzNVQfQ_",
    "outputId": "3a11e43c-be32-4541-d2b9-adb292223e83"
   },
   "outputs": [],
   "source": [
    "covid_data = pd.read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\")\n",
    "\n",
    "covid_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RlHtXFWwnAk2"
   },
   "source": [
    "‚úèÔ∏è *Try loading another CSV dataset from [Berlin's Open Data Portal](https://daten.berlin.de/)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q5A-ESb8dyrs"
   },
   "source": [
    "### XML\n",
    "\n",
    "[XML](https://en.wikipedia.org/wiki/XML) (Extensible Markup Language) is a data format, which can have very different kinds of hierarchical structures. XML files are common in a wide variety of contexts, including libraries, and especially in situations, in which the interoperability of multiple systems by several vendors needs to be ensured.\n",
    "\n",
    "The üå≤ **ElementTree** module will help us to parse the elements contained in an XML file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZZDFbj7zns35"
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N7f3zyqLcCFR"
   },
   "source": [
    "As we have already retrieved the XML feed from Tagesschau (and saved it in the variable `tagesschau_xml`), we can now parse it directly from the string, i.e., using the method `ET.fromstring()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6390,
     "status": "ok",
     "timestamp": 1598364870744,
     "user": {
      "displayName": "Marian D√∂rk",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqiajTdRS6NXELnqFzS3NNM3uxy6nUDGSMCjvAjw=s64",
      "userId": "05248840544598202773"
     },
     "user_tz": -120
    },
    "id": "a_tk2R4RcOUA",
    "outputId": "f4d38296-54d4-45a1-c94a-cb640b069040"
   },
   "outputs": [],
   "source": [
    "tagesschau = ET.fromstring(tagesschau_xml)\n",
    "tagesschau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0dLGK8JZeMGQ"
   },
   "source": [
    "This gives the root element of the XML feed (and all its children) in the variable `tagesschau`. \n",
    "\n",
    "Going through all items with `findall` and within these with `find` for specific sub-elements, we can extract the publication date and time and the title of the respective item. In the following these elements are put together into the DataFrame `tagesschau_df`. Note that it helps to peek into the XML source of the feed to know the specific element names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6368,
     "status": "ok",
     "timestamp": 1598364870745,
     "user": {
      "displayName": "Marian D√∂rk",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqiajTdRS6NXELnqFzS3NNM3uxy6nUDGSMCjvAjw=s64",
      "userId": "05248840544598202773"
     },
     "user_tz": -120
    },
    "id": "2DOgw1FAy3k_",
    "outputId": "e2d565ec-50b6-47af-d5cd-3a55b6de3ef0"
   },
   "outputs": [],
   "source": [
    "# create two empty lists\n",
    "dates = []\n",
    "titles = []\n",
    "\n",
    "# go through all item elements in the tree\n",
    "for item in tagesschau.findall('.//item'):\n",
    "  # extract date information and titles\n",
    "  dates.append( item.find('.//pubDate').text )\n",
    "  titles.append( item.find('.//title').text )\n",
    "\n",
    "# create a dataframe containing the two columns\n",
    "tagesschau_df = pd.DataFrame(    \n",
    "    {'date': dates,\n",
    "     'title': titles,\n",
    "    })  \n",
    "\n",
    "tagesschau_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XZrj9B2PnHLz"
   },
   "source": [
    "‚úèÔ∏è *Each news item also contains a `description` element. Why not add a third column to the DataFrame?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "adgiES-8GtPg"
   },
   "source": [
    "## Examining\n",
    "\n",
    "You are now able to load and parse data from several formats. At this point, here are plenty of ways to inspect these datasets. We are going to try some simple methods to peek around the datasets. Once you have a tabular dataset ready as a DataFrame, there are quite a few convenient methods to view and explore its contents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Oqcw_IZEv3L"
   },
   "source": [
    "### Head & tail\n",
    "\n",
    "You could start with looking at the beginning of the dataset with `head()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10495,
     "status": "ok",
     "timestamp": 1598364874906,
     "user": {
      "displayName": "Marian D√∂rk",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqiajTdRS6NXELnqFzS3NNM3uxy6nUDGSMCjvAjw=s64",
      "userId": "05248840544598202773"
     },
     "user_tz": -120
    },
    "id": "-b-6QczauzyR",
    "outputId": "a4ad3feb-8211-4492-e1b5-e11d95f40d1b"
   },
   "outputs": [],
   "source": [
    "covid_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UjYbpgygmWFO"
   },
   "source": [
    "‚úèÔ∏è *What do you think happens, when you replace `head()` with `tail()` ?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZhpO2D13zare"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lfm3uCoTmTqZ"
   },
   "source": [
    "### Describe & info\n",
    "\n",
    "You can also ask Pandas to provide some statistical descriptions (which are only applied to the columns containing numeric data):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10482,
     "status": "ok",
     "timestamp": 1598364874907,
     "user": {
      "displayName": "Marian D√∂rk",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqiajTdRS6NXELnqFzS3NNM3uxy6nUDGSMCjvAjw=s64",
      "userId": "05248840544598202773"
     },
     "user_tz": -120
    },
    "id": "g7tmvt4Lmi5-",
    "outputId": "0016c7a5-2bb4-40f4-8ae4-9ce406235eb0"
   },
   "outputs": [],
   "source": [
    "covid_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XZoDMYJ_tfWB"
   },
   "source": [
    "This may not seem that useful to you yet. You may want to know what kind of datatypes the different columns contain and how many values are present. For this the `info()` method will be of help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 969
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10470,
     "status": "ok",
     "timestamp": 1598364874908,
     "user": {
      "displayName": "Marian D√∂rk",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqiajTdRS6NXELnqFzS3NNM3uxy6nUDGSMCjvAjw=s64",
      "userId": "05248840544598202773"
     },
     "user_tz": -120
    },
    "id": "Q74i1KdvoO7g",
    "outputId": "542ae020-82bb-4da4-dbe5-de66a136a3da"
   },
   "outputs": [],
   "source": [
    "covid_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rk29BztPAVcX"
   },
   "source": [
    "With this it is now possible to access specific columns by using their names.  But did you notice the long label for the first column? Let's rename the column `human_development_index` into something short and sweet such as: `hdi`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4cb4w4FeAbQq"
   },
   "outputs": [],
   "source": [
    "covid_data = covid_data.rename(columns={\"human_development_index\": \"hdi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aKnvJFExnhpL"
   },
   "source": [
    "‚úèÔ∏è *Do you want to rename any other columns?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p4He-0T8zppE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DdG-stZV0JWz"
   },
   "source": [
    "### Select & query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kj_SJAC_0e4c"
   },
   "source": [
    "We can select an individual column using single [square brackets]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10439,
     "status": "ok",
     "timestamp": 1598364874909,
     "user": {
      "displayName": "Marian D√∂rk",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqiajTdRS6NXELnqFzS3NNM3uxy6nUDGSMCjvAjw=s64",
      "userId": "05248840544598202773"
     },
     "user_tz": -120
    },
    "id": "lsYAH1cu0foN",
    "outputId": "7d9f6b00-5253-4c5b-ff77-7f511e3c5590"
   },
   "outputs": [],
   "source": [
    "covid_data[\"hdi\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BpOYViZF0WTC"
   },
   "source": [
    "‚Ä¶¬†and we can select multiple columns using nested [[square brackets]]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10412,
     "status": "ok",
     "timestamp": 1598364874909,
     "user": {
      "displayName": "Marian D√∂rk",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqiajTdRS6NXELnqFzS3NNM3uxy6nUDGSMCjvAjw=s64",
      "userId": "05248840544598202773"
     },
     "user_tz": -120
    },
    "id": "gxxYaH_r0bWP",
    "outputId": "12723375-ac11-44e0-a1ad-a8212b748fa8"
   },
   "outputs": [],
   "source": [
    "covid_data[[\"hdi\", \"life_expectancy\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84LW2qoWnsrW"
   },
   "source": [
    "‚úèÔ∏è *Which columns interest you? Replace `hdi` and `life_expectancy` with other column labels* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R-6AMfHUqYCd"
   },
   "source": [
    "Note that the `life_expectancy` columns contains a lot of `NaN` - this stands for \"Not a Number\" and it means here that values are missing.\n",
    "\n",
    "In order to focus on the rows which do have missing data, we can squeeze in a requirement that we only want those rows, where the values in both above used columns are not missing, i.e., `notnull()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VVrgqKBYlhJc"
   },
   "source": [
    "‚úèÔ∏è *Formulate a query on another column:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jRPD_yB0z6Rh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GtlRXt_PsGOg"
   },
   "source": [
    "There are four related methods for accessing rows, columns, and specific values, either by integer positons (iloc and iat) or by the labels (that is what is displayed in bold above).\n",
    "\n",
    "- `loc`: access rows and columns by label\n",
    "- `iloc`: access rows and columns by integer position \n",
    "- `at`: access a single value for a row/column label pair\n",
    "- `iat`: access a single value for a row/column pair by integer position \n",
    "\n",
    "For example, this way we can get the first entry in the `covid_data` DataFrame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10382,
     "status": "ok",
     "timestamp": 1598364874911,
     "user": {
      "displayName": "Marian D√∂rk",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqiajTdRS6NXELnqFzS3NNM3uxy6nUDGSMCjvAjw=s64",
      "userId": "05248840544598202773"
     },
     "user_tz": -120
    },
    "id": "bMWeSrCbtQp7",
    "outputId": "7147a158-695d-4d53-bb9e-db491110e826"
   },
   "outputs": [],
   "source": [
    "covid_data.loc[0]\n",
    "\n",
    "# because the index here uses integers, iloc and loc do the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "odyKUoYOvqAv"
   },
   "source": [
    "Finally, you can also retrieve rows that match a query. With this we are retrieving the rows with new cases for Germany:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10368,
     "status": "ok",
     "timestamp": 1598364874912,
     "user": {
      "displayName": "Marian D√∂rk",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhqiajTdRS6NXELnqFzS3NNM3uxy6nUDGSMCjvAjw=s64",
      "userId": "05248840544598202773"
     },
     "user_tz": -120
    },
    "id": "vxE4SwnBvvHT",
    "outputId": "426239ec-fc58-4c37-f322-7c7c9af8705f"
   },
   "outputs": [],
   "source": [
    "covid_data[covid_data['location'].str.contains('Germany')] [\"new_cases\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume we have a dataframe like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = pd.DataFrame({\n",
    " 'day': list(range(100)),\n",
    " 'Hagworts': np.random.randint(0, 500, 100).cumsum(), \n",
    " 'William Wunder\\'s Factory' : np.random.randint(0, 100, 100).cumsum(),\n",
    " 'Lotham' : np.random.randint(0, 1000, 100).cumsum()   \n",
    "})\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to show that in the form of a line graph, we have one Problem! Which column do we select as the y axis???\n",
    "\n",
    "Fortunately, Pandas comes to help! Using ```melt``` we can merge multiple columns into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = data.melt('day')\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(merged_data).mark_line().encode(\n",
    "    x = 'day',\n",
    "    y = 'value',\n",
    "    color = 'variable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5vcAaftO1He8"
   },
   "source": [
    "‚úèÔ∏è *Now it's time for a challenge!*\n",
    "\n",
    "Try to visualize the positive cases per million over time for three countries of your choosing! There are several steps to it: First you need to convert the date column to a pandas date column using ```pd.to_datetime```, then you filter by the countries and finally you can visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PyJgW6U-DtiX"
   },
   "source": [
    "## Sources\n",
    "- [Pandas Tutorial: DataFrames in Python - DataCamp](https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python)\n",
    "- [The ElementTree XML API](https://docs.python.org/2/library/xml.etree.elementtree.html)\n",
    "- [Where do Mayors Come From? Querying Wikidata with Python and SPARQL - Towards Data Science](https://towardsdatascience.com/where-do-mayors-come-from-querying-wikidata-with-python-and-sparql-91f3c0af22e2)\n",
    "- [Examining Data Using Pandas | Linux Journal](https://www.linuxjournal.com/content/examining-data-using-pandas)\n",
    "- [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "infovis1start.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "nteract": {
   "version": "0.22.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
